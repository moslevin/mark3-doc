<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mark3 Realtime Kernel: Mark3 Kernel Architecture</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Mark3 Realtime Kernel
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('_m_a_r_k3_k_a.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title"><a class="el" href="namespace_mark3.html">Mark3</a> Kernel Architecture </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="MARK3KAOVER"></a>
Overview</h1>
<p>At a high level, the <a class="el" href="namespace_mark3.html">Mark3</a> RTOS is organized into the following features, and layered as shown below:</p>
<div class="image">
<img src="Mark3_arch4.png" alt="Mark3_arch4.png"/>
</div>
 <p>Everything in the “green” layer represents the <a class="el" href="namespace_mark3.html">Mark3</a> public API and classes, beneath which lives all hardware abstraction and CPU-specific porting and driver code, which runs on a given target CPU.</p>
<p>The features and concepts introduced in this diagram can be described as follows:</p>
<p><b>Threads:</b> The ability to multiplex the CPU between multiple tasks to give the perception that multiple programs are running simultaneously. Each thread runs in its own context with its own stack.</p>
<p><b>Scheduler:</b> Algorithm which determines the thread that gets to run on the CPU at any given time. This algorithm takes into account the priorites (and other execution parameters) associated with the threads in the system.</p>
<p><b>IPC:</b> Inter-process-communications. Message-passing and Mailbox interfaces used to communicate between threads synchronously or asynchronously.</p>
<p><b>Synchronization Objects:</b> Ability to schedule thread execution relative to system conditions and events, allowing for sharing global data and resources safely and effectively.</p>
<p><b>Timers:</b> High-resolution software timers that allow for actions to be triggered on a periodic or one-shot basis.</p>
<p><b>Profiler:</b> Special timer used to measure the performance of arbitrary blocks of code.</p>
<p><b>Debugging:</b> Realitme logging and trace functionality, facilitating simplified debugging of systems using the OS.</p>
<p><b>Atomics:</b> Support for UN-interruptble arithmatic operations.</p>
<p><b>Driver API:</b> Hardware abstraction interface allowing for device drivers to be written in a consistent, portable manner.</p>
<p><b>Hardware Abstraction Layer:</b> Class interface definitions to represent threading, context-switching, and timers in a generic, abstracted manner.</p>
<p><b>Porting Layer:</b> Class interface implementation to support threading, context-switching, and timers for a given CPU.</p>
<p><b>User Drivers:</b> Code written by the user to implement device-specific peripheral drivers, built to make use of the <a class="el" href="namespace_mark3.html">Mark3</a> driver API.</p>
<p>Each of these features will be described in more detail in the following sections of this chapter.</p>
<p>The concepts introduced in the above architecture are implemented in a variety of source modules, which are logically broken down into classes (or in some cases, groups of functions/macros). The relationship between objects in the <a class="el" href="namespace_mark3.html">Mark3</a> kernel is shown below:</p>
<div class="image">
<img src="Mark3_arch5.png" alt="Mark3_arch5.png"/>
</div>
 <p>The objects shown in the preceding table can be grouped together by feature. In the table below, we group each feature by object, referencing the source module in which they can be found in the <a class="el" href="namespace_mark3.html">Mark3</a> source tree.</p>
<table class="doxtable">
<tr>
<th align="left">Feature </th><th align="left">Kernel Object </th><th align="left">Source Files  </th></tr>
<tr>
<td align="left">Profiling </td><td align="left">ProfileTimer </td><td align="left"><a class="el" href="profile_8cpp.html" title="Code profiling utilities. ">profile.cpp</a>/.h </td></tr>
<tr>
<td align="left">Threads + Scheduling </td><td align="left">Thread </td><td align="left"><a class="el" href="thread_8cpp.html" title="Platform-Independent thread class Definition. ">thread.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">Scheduler </td><td align="left"><a class="el" href="scheduler_8cpp.html" title="Strict-Priority + Round-Robin thread scheduler implementation. ">scheduler.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">PriorityMap </td><td align="left"><a class="el" href="priomap_8cpp.html" title="Priority map data structure. ">priomap.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">Quantum </td><td align="left"><a class="el" href="quantum_8cpp.html" title="Thread Quantum Implementation for Round-Robin Scheduling. ">quantum.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">ThreadPort </td><td align="left"><a class="el" href="threadport_8cpp.html" title="ATMega1284p Multithreading. ">threadport.cpp</a>/.h ** </td></tr>
<tr>
<td align="left"></td><td align="left">KernelSWI </td><td align="left"><a class="el" href="kernelswi_8cpp.html" title="Kernel Software interrupt implementation for ATMega328p. ">kernelswi.cpp</a>/.h ** </td></tr>
<tr>
<td align="left">Timers </td><td align="left">Timer </td><td align="left"><a class="el" href="timer_8h.html" title="Timer object declarations. ">timer.h</a>/timer.cpp </td></tr>
<tr>
<td align="left"></td><td align="left">TimerScheduler </td><td align="left"><a class="el" href="timerscheduler_8h.html" title="Timer scheduler declarations. ">timerscheduler.h</a> </td></tr>
<tr>
<td align="left"></td><td align="left">TimerList </td><td align="left"><a class="el" href="timerlist_8h.html" title="Timer list declarations. ">timerlist.h</a>/cpp </td></tr>
<tr>
<td align="left"></td><td align="left">KernelTimer </td><td align="left"><a class="el" href="kerneltimer_8cpp.html" title="Kernel Timer Implementation for ATMega328p. ">kerneltimer.cpp</a>/.h ** </td></tr>
<tr>
<td align="left">Synchronization </td><td align="left">BlockingObject </td><td align="left"><a class="el" href="blocking_8cpp.html" title="Implementation of base class for blocking objects. ">blocking.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">Semaphore </td><td align="left"><a class="el" href="ksemaphore_8cpp.html" title="Semaphore Blocking-Object Implemenation. ">ksemaphore.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">EventFlag </td><td align="left"><a class="el" href="eventflag_8cpp.html" title="Event Flag Blocking Object/IPC-Object implementation. ">eventflag.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">Mutex </td><td align="left"><a class="el" href="mutex_8cpp.html" title="Mutual-exclusion object. ">mutex.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">Notify </td><td align="left"><a class="el" href="notify_8cpp.html" title="Lightweight thread notification - blocking object. ">notify.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">ConditionVariable </td><td align="left"><a class="el" href="condvar_8cpp.html" title="Condition Variable implementation. ">condvar.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">ReaderWriterLock </td><td align="left"><a class="el" href="readerwriter_8cpp.html" title="Reader-writer lock implementation. ">readerwriter.cpp</a>/.h </td></tr>
<tr>
<td align="left">IPC/Message-passing </td><td align="left">Mailbox </td><td align="left"><a class="el" href="mailbox_8cpp.html" title="Mailbox + Envelope IPC mechanism. ">mailbox.cpp</a>/.h </td></tr>
<tr>
<td align="left"></td><td align="left">MessageQueue </td><td align="left"><a class="el" href="message_8cpp.html" title="Inter-thread communications via message passing. ">message.cpp</a>/.h </td></tr>
<tr>
<td align="left">Debugging </td><td align="left">Miscellaneous Macros </td><td align="left"><a class="el" href="kerneldebug_8h.html" title="Macros and functions used for assertions, kernel traces, etc. ">kerneldebug.h</a> </td></tr>
<tr>
<td align="left">Atomic Operations </td><td align="left">Atomic </td><td align="left"><a class="el" href="atomic_8cpp.html" title="Basic Atomic Operations. ">atomic.cpp</a>/.h </td></tr>
<tr>
<td align="left">Kernel </td><td align="left">Kernel </td><td align="left"><a class="el" href="kernel_8cpp.html" title="Kernel initialization and startup code. ">kernel.cpp</a>/.h </td></tr>
</table>
<pre class="fragment">** implementation is platform-dependent, and located under the kernel's
** /cpu/&lt;arch&gt;/&lt;variant&gt;/&lt;toolchain&gt; folder in the source tree
</pre><h1><a class="anchor" id="THREADSCHED"></a>
Threads and Scheduling</h1>
<p>The classes involved in threading and scheudling in <a class="el" href="namespace_mark3.html">Mark3</a> are highlighted in the following diagram, and are discussed in detail in this chapter:</p>
<div class="image">
<img src="Mark3_arch24.png" alt="Mark3_arch24.png"/>
</div>
 <h2><a class="anchor" id="BITTHREAD"></a>
A Bit About Threads</h2>
<p>Before we get started talking about the internals of the <a class="el" href="namespace_mark3.html">Mark3</a> scheduler, it's necessary to go over some background material - starting with: what is a thread, anyway?</p>
<p>Let's look at a very basic CPU without any sort of special multi-threading hardware, and without interrupts. When the CPU is powered up, the program counter is loaded with some default location, at which point the processor core will start executing instructions sequentially - running forever and ever according to whatever has been loaded into program memory. This single instance of a simple program sequence is the only thing that runs on the processor, and the execution of the program can be predicted entirely by looking at the CPU's current register state, its program, and any affected system memory (the CPU's "context").</p>
<p>It's simple enough, and that's exactly the definition we have for a thread in an RTOS.</p>
<p>Each thread contains an instance of a CPU's register context, its own stack, and any other bookkeeping information necessary to define the minimum unique execution state of a system at runtime. It is the job of a RTOS to multiplex the execution of multiple threads on a single physical CPU, thereby creating the illusion that many programs are being executed simultaneously. In reality there can only ever be one thread truly executing at any given moment on a CPU core, so it's up to the scheduler to set and enforce rules about what thread gets to run when, for how long, and under what conditions. As mentioned earlier, any system without an RTOS exeuctes as a single thread, so at least two threads are required for an RTOS to serve any useful purpose.</p>
<p>Note that all of this information is is common to pretty well every RTOS in existence - the implementation details, including the scheduler rules, are all part of what differentiates one RTOS from another.</p>
<h2><a class="anchor" id="THREADLISTS"></a>
Thread States and ThreadLists</h2>
<p>Since only one thread can run on a CPU at a time, the scheduler relies on thread information to make its decisions. <a class="el" href="namespace_mark3.html">Mark3</a>'s scheduler relies on a variety of such information, including:</p>
<ul>
<li>The thread's current priority</li>
<li>Round-Robin execution quanta</li>
<li>Whether or not the thread is blocked on a synchronization object, such as a mutex or semaphore</li>
<li>Whether or not the thread is currently suspended</li>
</ul>
<p>The scheduler further uses this information to logically place each thread into 1 of 4 possible states: </p><pre class="fragment">- Ready - The thread is currently running
- Running - The thread is able to run
- Blocked - The thread cannot run until a system condition is met
- Stopped - The thread cannot run because its execution has been suspended
.
</pre><p>In order to determine a thread's state, threads are placed in "buckets" corresponding to these states. Ready and running threads exist in the scheduler's buckets, blocked threads exist in a bucket belonging to the object they're blocked on, and stopped threads exist in a separate bucket containing all stopped threads.</p>
<p>In reality, the various buckets are just doubly-linked lists of Thread objects - implemented in something called the ThreadList class. To facilitate this, the Thread class directly inherits from a LinkListNode class, which contains the node pointers required to implement a doubly-linked list. As a result, Threads may be effortlessly moved from one state to another using efficient linked-list operations built into the ThreadList class.</p>
<h2><a class="anchor" id="BLOCKUNBLOCK"></a>
Blocking and Unblocking</h2>
<p>While many developers new to the concept of an RTOS assume that all threads in a system are entirely separate from eachother, the reality is that practical systems typically involve multiple threads working together, or at the very least sharing resources. In order to synchronize the execution of threads for that purpose, a number of synchronization primatives (blocking objects) are implemented to create specific sets of conditions under which threads can continue execution. The concept of "blocking" a thread until a specific condition is met is fundamental to understanding RTOS applications design, as well as any highly-multithreaded applications.</p>
<h2><a class="anchor" id="BLOCKOBJ"></a>
Blocking Objects</h2>
<p>Blocking objects and primatives provided by <a class="el" href="namespace_mark3.html">Mark3</a> include:</p>
<ul>
<li>Semaphores (binary and counting)</li>
<li>Mutexes</li>
<li>Event Flags</li>
<li>Thread Notification Objects</li>
<li>Thread Sleep</li>
<li>Message Queues</li>
<li>Mailboxes</li>
</ul>
<p>The relationship between these objects in the system are shown below:</p>
<div class="image">
<img src="Mark3_arch21.png" alt="Mark3_arch21.png"/>
</div>
 <p>Each of these objects inherit from the BlockingObject class, which itself contains a ThreadList object. This class contains methods to Block() a thread (remove it from the Scheduler's "Ready" or "Running" ThreadLists), as well as UnBlock() a thread (move a thread back to the "Ready" lists). This object handles transitioning threads from list-to-list (and state-to-state), as well as taking care of any other Scheduler bookkeeping required in the process. While each of the Blocking types implement a different condition, they are effectively variations on the same theme. Many simple Blocking objects are also used to build complex blocking objects - for instance, the Thread Sleep mechanism is essentially a binary semaphore and a timer object, while a message queue is a linked-list of message objects combined with a semaphore.</p>
<h1><a class="anchor" id="INSIDESCHED"></a>
Inside the Mark3 Scheduler</h1>
<p>At this point we've covered the following concepts:</p>
<ul>
<li>Threads</li>
<li>Thread States and Thread Lists</li>
<li>Blocking and Un-Blocking Threads</li>
</ul>
<p>Thankfully, this is all the background required to understand how the <a class="el" href="namespace_mark3.html">Mark3</a> Scheduler works. In technical terms, <a class="el" href="namespace_mark3.html">Mark3</a> implements "strict priority
scheduling, with round-robin scheduling among threads in each priority group". In plain English, this boils down to a scheduler which follows a few simple rules:</p>
<pre class="fragment">    Find the highest-priority "Ready" list that has at least one Thread.
    Select the next thread to run as the first thread in that list
</pre><p>Since context switching is one of the most common and frequent operation performed by an RTOS, this needs to be as fast and deterministic as possible. While the logic is simple, a lot of care must be put into optimizing the scheduler to achieve those goals. In the section below we discuss the optimization approaches taken in <a class="el" href="namespace_mark3.html">Mark3</a>.</p>
<p>There are a number of ways to find the highest-priority thread. The naive approach would be to simply iterate through the scheduler's array of ThreadLists from highest to lowest, stopping when the first non-empty list is found, such as in the following block of code:</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (prio = num_prio - 1; prio &gt;= 0; prio--)</div><div class="line">{</div><div class="line">    <span class="keywordflow">if</span> (thread_list[prio].get_head() != <span class="keyword">nullptr</span>)</div><div class="line">    {</div><div class="line">        <span class="keywordflow">break</span>;</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>While that would certainly work and be sufficient for a variety of systems, it's a non-deterministic approach (complexity O(n)) whose cost varies substantially based on how many priorities have to be evaluated. It's simple to read and understand, but it's non-optimal.</p>
<p>Fortunatley, a functionally-equivalent and more deterministic approach can be implemented with a few tricks.</p>
<p>In addition to maintaining an array of ThreadLists, <a class="el" href="namespace_mark3.html">Mark3</a> also maintains a bitmap (one bit per priority level) that indicates which thread lists have ready threads. This bitmap is maintained automatically by the ThreadList class, and is updated every time a thread is moved to/from the Scheduler's ready lists.</p>
<p>By inspecting this bitmap using a technique to count the leading zero bits in the bitmap, we determine which threadlist to choose in fixed time.</p>
<p>Now, to implement the leading-zeros check, this can once again be performed iteratively using bitshifts and compares (which isn't any more efficient than the raw list traversal), but it can also be evaluated using either a lookup table, or via a special CPU instruction to count the leading zeros in a value. In <a class="el" href="namespace_mark3.html">Mark3</a>, we use all approaches. In the event a target architecture or toolchain has intrinsic support for a count-leading-zeroes (CLZ) instruction, that implementation is used. Otherwise, a software-based implementation is provided &ndash; either using a lookup table, or a bitshift-and-compare algorithm.</p>
<p>(As a sidenote - this is actually a very common approach used in OS schedulers. It's actually part of the reason why modern ARM cores implement a dedicated count-leading-zeros [CLZ] instruction!)</p>
<p>For the lookup-table approach - a 4-bit lookup table can be used with an 8-bit priority-level bitmap would look something like this:</p>
<div class="fragment"><div class="line"><span class="comment">// Check the highest 4 priority levels, represented in the</span></div><div class="line"><span class="comment">// upper 4 bits in the bitmap</span></div><div class="line">priority = priority_lookup_table[(priority_bitmap &gt;&gt; 4)];</div><div class="line"></div><div class="line"><span class="comment">// priority is non-zero if we found something there</span></div><div class="line"><span class="keywordflow">if</span>( priority )</div><div class="line">{</div><div class="line">    <span class="comment">// Add 4 because we were looking at the higher levels</span></div><div class="line">    priority += 4;</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span></div><div class="line">{</div><div class="line">    <span class="comment">// Nothing in the upper 4, look at the lowest 4 priority levels</span></div><div class="line">    <span class="comment">// represented by the lowest 4 bits in the bitmap</span></div><div class="line">    priority = priority_lookup_table[priority_bitmap &amp; 0x0F];</div><div class="line">}</div></div><!-- fragment --><p>Deconstructing this algorithm, you can see that the priority lookup will have on O(1) complexity - and is extremely low-cost.</p>
<p>This operation is thus fully deterministic and time bound - no matter how many threads are scheduled, the operation will always be time-bound to the most expensive of these two code paths. Even with only 8 priority levels, this is still much faster than iteratively checking the thread lists manually, compared with the previous example implementation.</p>
<p>Once the priority level has been found, selecting the next thread to run is trivial, consisting of something like this:</p>
<p>next_thread = thread_list[prio].get_head();</p>
<p>In the case of the get_head() calls, this evaluates to an inline-load of the "head" pointer in the particular thread list.</p>
<p>One important thing to take away from this analysis is that the scheduler is only responsible for selecting the next-to-run thread. In fact, these two operations are totally decoupled - no context switching is performed by the scheduler, and the scheduler isn't called from the context switch. The scheduler simply produces new "next thread" values that are consumed from within the context switch code.</p>
<h2><a class="anchor" id="RRSCHED"></a>
Considerations for Round-Robin Scheduling</h2>
<p>One thing that isn't considered directly from the scheduler algorithm is the problem of dealing with multiple threads within a single priority group; all of the alorithms that have been explored above simply look at the first Thread in each group.</p>
<p><a class="el" href="namespace_mark3.html">Mark3</a> addresses this issue indirectly, using an optimized software timer to manage round-robin scheduling, as follows.</p>
<p>In some instances where the scheduler is run by the kernel directly (typically as a result of calling Thread::Yield()), the kernel will perfom an additional check after running the Scheduler to determine whether or there are multiple ready Threads in the priority of the next ready thread.</p>
<p>If there are multiple threads within that priority, the kernel starts a one-shot software timer which is programmed to expire at the next Thread's configured quantum. When this timer expires, a timer callback function executes to perform two simple operations:</p>
<p>"Pivot" the current Thread's priority list. Set a flag telling the kernel to trigger a Yield after exiting the main TimerScheduler processing loop</p>
<p>Pivoting the thread list basically moves the head of a circular-linked-list to its next value, which in our case ensures that a new thread will be chosen the next time the scheduler is run (the scheduler only looks at the head node of the priority lists). And by calling Yield, the system forces the scheduler to run, a new round-robin software timer to be installed (if necssary), and triggers a context switch SWI to load the newly-chosen thread. Note that if the thread attached to the round-robin timer is pre-empted, the kernel will take steps to abort and invalidate that round-robin software timer, installing a new one tied to the next thread to run if necessary.</p>
<p>Because the round-robin software timer is dynamically installed when there are multiple ready threads at the highest ready priority level, there is no CPU overhead with this feature unless that condition is met. The cost of round-robin scheduling is also fixed - no matter how many threads there are, and the cost is identical to any other one-shot software timer in the system.</p>
<h2><a class="anchor" id="CONSWITCH"></a>
Context Switching</h2>
<p>There's really not much to say about the actual context switch operation at a high level. Context switches are triggered whenever it has been determined that a new thread needs to be swapped into the CPU core when the scheduler is run. <a class="el" href="namespace_mark3.html">Mark3</a> implements also context switches as a call to a software interrupt - on AVR platforms, we typically use INT0 or INT2 for this (although any pin-change GPIO interrupt can be used), and on ARM we achieve this by triggering a PendSV exception.</p>
<p>However, regardless of the architecture, the contex-switch ISR will perform the following three operations:</p>
<p>Save the current Thread's context to the current Thread stack Make the "next to run" thread the "currently running" thread Restore the context of the next Thread from the Thread stack</p>
<p>The code to implement the context switch is entirely architecture-specific, so it won't be discussed in detail here. It's almost always gory inline-assembly which is used to load and store various CPU registers, and is highly-optimized for speed. We dive into an example implementation for the ARM Cortex-M0 microcontroller in a later section of this book.</p>
<h2><a class="anchor" id="ALLTOGETHER"></a>
Putting It All Together</h2>
<p>In short, we can say that the <a class="el" href="namespace_mark3.html">Mark3</a> scheduler works as follows:</p>
<ul>
<li>The scheduler is run whenever a Thread::Yield() is called by a user, as part of blocking calls, or whenever a new thread is started</li>
<li>The <a class="el" href="namespace_mark3.html">Mark3</a> scheduler is deterministic, selecting the next thread to run in fixed-time</li>
<li>The scheduler only chooses the next thread to run, the context switch SWI consumes that information to get that thread running</li>
<li>Where there are multiple ready threads in the highest populated priority level, a software timer is used to manage round-robin scheduling</li>
</ul>
<p>While we've covered a lot of ground in this section, there's not a whole lot of code involved. However, the code that performs these operations is nuanced and subtle. If you're interested in seeing how this all works in practice, I suggest reading through the <a class="el" href="namespace_mark3.html">Mark3</a> source code (which is heavily annotated), and stepping through the code with a simulator/emulator.</p>
<h1><a class="anchor" id="ARCHTIMERS"></a>
Timers</h1>
<p><a class="el" href="namespace_mark3.html">Mark3</a> implements one-shot and periodic software-timers via the Timer class. The user configures the timer for duration, repetition, and action, at which point the timer can be activated. When an active timer expires, the kernel calls a user-specified callback function, and then reloads the timer in the case of periodic timers. The same timer objects exposed to the user are also used within the kernel to implement round-robin scheduling, and timeout-based APIs for seamphores, mutexes, events, and messages.</p>
<p>Timers are implemented using the following components in the <a class="el" href="namespace_mark3.html">Mark3</a> Kernel:</p>
<div class="image">
<img src="Mark3_arch20.png" alt="Mark3_arch20.png"/>
</div>
 <p>The Timer class provides the basic periodic and one-shot timer functionality used by applicaiton code, blocking objects, and IPC.</p>
<p>The TimerList class implements a doubly-linked list of Timer objects, and the logic required to implement a timer tick (tick-based kernel) or timer expiry (tickless kernel) event.</p>
<p>The TimerScheduler class contains a single TimerList object, implementing a single, system-wide list of Timer objects within the kernel. It also provides hooks for the hardware timer, such that when a timer tick or expiry event occurs, the TimerList expiry handler is run.</p>
<p>The KernelTimer class (<a class="el" href="kerneltimer_8cpp.html" title="Kernel Timer Implementation for ATMega328p. ">kerneltimer.cpp</a>/.h) implements the CPU specific hardware timer driver that is used by the kernel and the TimerScheduler to implement software timers.</p>
<p>While extremely simple to use, they provide one of the most powerful execution contexts in the system.</p>
<p>The software timers implemented in <a class="el" href="namespace_mark3.html">Mark3</a> use interrupt-nesting within the kernel timer's interrupt handler. This context is be considered higher-priority than the highest priority user thread, but lower-priority than other interrupts in the system. As a result, this minimizes critical interrupt latency in the system, albeit at the expense of responsiveness of the user-threads.</p>
<p>For this reason, it's critical to ensure that all timer callback events are kept as short as possible to prevent adding thread-level latency. All heavy-lifting should be left to the threads, so the callback should only implement signalling via IPC or synchronization object.</p>
<p>The time spent in this interrupt context is also dependent on the number of active timers at any given time. However, <a class="el" href="namespace_mark3.html">Mark3</a> also can be used to minimize the frequency of these interrupts wakeups, by using an optional “tolerance” parameter in the timer API calls. In this way, periodic tasks that have less rigorous real-time constraints can all be grouped together – executing as a group instead of one-after-another.</p>
<p><a class="el" href="namespace_mark3.html">Mark3</a> also contains two different timer implementations that can be configured at build-time, each with their own advantages.</p>
<h2><a class="anchor" id="TICKBASEDTIMERS"></a>
Tick-based Timers</h2>
<p>In a tick-based timing scheme, the kernel relies on a system-timer interrupt to fire at a relatively-high frequency, on which all kernel timer events are derived. On modern CPUs and microcontrollers, a 1kHz system tick is common, although quite often lower frequencies such as 60Hz, 100Hz, or 120Hz are used. The resolution of this timer also defines the maximum resolution of timer objects as a result. That is, if the timer frequency is 1kHz, a user cannot specify a timer resolution lowerthan 1ms.</p>
<p>The advantage of a tick-based timer is its sheer simplicity. It typically doesn't take much to set up a timer to trigger an interrupt at a fixed-interval, at which point, all system timer intervals are decremented by 1 count. When each system timer interval reaches zero, a callback is called for the event, and the events are either reset and restarted (repeated timers) or cleared (1-shot).</p>
<p>Unfortunately, that simplicity comes at a cost of increased interrupt count, which cause frequent CPU wakeups and utilization, and power consumption.</p>
<h2><a class="anchor" id="TICKLESSTIMERS"></a>
Tickless Timers</h2>
<p>Note: Tickless timers are removed as of the R7 release. The below documentation is preserved for historical information only. The reason for removing tickless timers include the overhead associated with managing those timers (significantly more math and management is involved). In practice, there are few scenarios where purely tickless timers add benefit - beyond the most constrained devices. Also, it is entirely possible to disable software timers from the idle task when lower power/fewer interrupts are desired in most cases where a tickless timer would be of value. </p><hr/>
<p>In a tickless system, the kernel timer only runs when there are active timers pending expiry, and even then, the timer module only generates interrupts when a timer expires, or a timer reaches its maximum count value. Additionally, when there are no active timer objects, the timer can is completely disabled – saving even more cycles, power, and CPU wakeups. These factors make the tickless timer approach a highly-optimal solution, suitable for a wide array of low-power applications.</p>
<p>Also, since tickless timers do not rely on a fixed, periodic clock, they can potentially be higher resolution. The only limitation in timer resolution is the precision of the underlying hardware timer as configured. For example, if a 32kHz hardware timer is being used to drive the timer scheduler, the resolution of timer objects would be in the ~33us range.</p>
<p>The only downside of the tickless timer system is an added complexity to the timer code, requiring more code space, and slightly longer execution of the timer routines when the timer interrupt is executed.</p>
<h2><a class="anchor" id="TIMERPA"></a>
Timer Processing Algorithm</h2>
<p>Timer interrupts occur at either a fixed-frequency (tick-based), or at the next timer expiry interval (tickless), at which point the timer processing algorithm runs. While the timer count is reset by the timer-interrupt, it is still allowed to accumulate ticks while this algorithm is executed in order to ensure that timer-accuracy is kept in real-time. It is also important to note that round-robin scheduling changes are disabled during the execution of this algorithm to prevent race conditions, as the round-robin code also relies on timer objects.</p>
<p>All active timer objects are stored in a doubly-linked list within the timer-scheduler, and this list is processed in two passes by the alogirthm which runs from the timer-interrupt (with interrupt nesting enabled). The first pass determines which timers have expired and the next timer interval, while the second pass deals with executing the timer callbacks themselves. Both phases are discussed in more detail below.</p>
<p>In the first pass, the active timers are decremented by either 1 tick (tick-based), or by the duration of the last elapsed timer interval (tickless). Timers that have zero (or less-than-zero) time remaining have a “callback” flag set, telling the algorithm to call the timer's callback function in the second pass of the loop. In the event of a periodic timer, the timer's interval is reset to its starting value.</p>
<p>For the tickless case, the next timer interval is also computed in the first-pass by looking for the active timer with the least amount of time remaining in its interval. Note that this calculation is irrelevant in the tick-based timer code, as the timer interrupt fires at a fixed-frequency.</p>
<p>In the second pass, the algorithms loops through the list of active timers, looking for those with their “callback” flag set in the first pass. The callback function is then executed for each expired timer, and the “callback” flag cleared. In the event that a non-periodic (one-shot) timer expires, the timer is also removed from the timer scheduler at this time.</p>
<p>In a tickless system, once the second pass of the loop has been completed, the hardware timer is checked to see if the next timer interval has expired while processing the expired timer callbacks. In that event, the complete algorithm is re-run to ensure that no expired timers are missed. Once the algorithm has completed without the next timer expiring during processing, the expiry time is programmed into the hardware timer. Round-robin scheduling is re-enabled, and if a new thread has been scheduled as a result of action taken during a timer callback, a context switch takes place on return from the timer interrupt.</p>
<h1><a class="anchor" id="SYNCHIPC"></a>
Synchronization and IPC</h1>
<div class="image">
<img src="Mark3_arch21.png" alt="Mark3_arch21.png"/>
</div>
 <h1><a class="anchor" id="BLOCKINGOBJECTS"></a>
Blocking Objects</h1>
<p>A Blocking object in <a class="el" href="namespace_mark3.html">Mark3</a> is essentially a thread list. Any blocking object implementation (being a semaphore, mutex, event flag, etc.) canbe built on top of this class, utilizing the provided functions to manipulate thread location within the Kernel.</p>
<p>Blocking a thread results in that thread becoming de-scheduled, placed in the blocking object's own private list of threads which are waiting on the object.</p>
<p>Unblocking a thread results in the reverse: The thread is moved back to its original location from the blocking list.</p>
<p>The only difference between a blocking object based on this class is the logic used to determine what consitutes a Block or Unblock condition.</p>
<p>For instance, a semaphore Pend operation may result in a call to the Block() method with the currently-executing thread in order to make that thread wait for a semaphore Post. That operation would then invoke the UnBlock() method, removing the blocking thread from the semaphore's list, and back into the appropriate thread inside the scheduler.</p>
<p>Care must be taken when implementing blocking objects to ensure that critical sections are used judiciously, otherwise asynchronous events like timers and interrupts could result in non-deterministic and often catastrophic behavior.</p>
<p><a class="el" href="namespace_mark3.html">Mark3</a> implements a variety of blocking objects including semaphores, mutexes, event flags, and IPC mechanisms that all inherit from the basic Blocking-object class found in <a class="el" href="blocking_8h.html" title="Blocking object base class declarations. ">blocking.h</a>/cpp, ensuring consistency and a high degree of code-reuse between components.</p>
<h2><a class="anchor" id="SEMAPHORES"></a>
Semaphores</h2>
<p>Semaphores are used to synchronized execution of threads based on the availability (and quantity) of application-specific resources in the system. They are extremely useful for solving producer-consumer problems, and are the method-of-choice for creating efficient, low latency systems, where ISRs post semaphores that are handled from within the context of individual threads. Semaphores can also be posted (but not pended) from within the interrupt context.</p>
<h2><a class="anchor" id="MUTEX"></a>
Mutex</h2>
<p>Mutexes (Mutual exclusion objects) are provided as a means of creating "protected sections" around a particular resource, allowing for access of these objects to be serialized. Only one thread can hold the mutex at a time</p><ul>
<li>other threads have to wait until the region is released by the owner thread before they can take their turn operating on the protected resource. Note that mutexes can only be owned by threads - they are not available to other contexts (i.e. interrupts). Calling the mutex APIs from an interrupt will cause catastrophic system failures.</li>
</ul>
<p>Note that these objects are recursive in <a class="el" href="namespace_mark3.html">Mark3</a> - that is, the owner thread can claim a mutex more than once. The caveat here is that a recursively-held mutex will not be released until a matching “release” call is made for each “claim” call.</p>
<p>Prioritiy inheritence is provided with these objects as a means to avoid prioritiy inversions. Whenever a thread at a priority than the mutex owner blocks on a mutex, the priority of the current thread is boosted to the highest-priority waiter to ensure that other tasks at intermediate priorities cannot artificically prevent progress from being made.</p>
<h2><a class="anchor" id="EVENTFLAG"></a>
Event Flags</h2>
<p>Event Flags are another synchronization object, conceptually similar to a semaphore.</p>
<p>Unlike a semaphore, however, the condition on which threads are unblocked is determined by a more complex set of rules. Each Event Flag object contains a 16-bit field, and threads block, waiting for combinations of bits within this field to become set.</p>
<p>A thread can wait on any pattern of bits from this field to be set, and any number of threads can wait on any number of different patterns. Threads can wait on a single bit, multiple bits, or bits from within a subset of bits within the field.</p>
<p>As a result, setting a single value in the flag can result in any number of threads becoming unblocked simultaneously. This mechanism is extremely powerful, allowing for all sorts of complex, yet efficient, thread synchronization schemes that can be created using a single shared object.</p>
<p>Note that Event Flags can be set from interrupts, but you cannot wait on an event flag from within an interrupt.</p>
<h2><a class="anchor" id="NOTIFICATION"></a>
Notification Objects</h2>
<p>Notification objects are the most lightweight of all blocking objects supplied by <a class="el" href="namespace_mark3.html">Mark3</a>.</p>
<p>using this blocking primative, one or more threads wait for the notification object to be signalled by code elsewhere in the system (i.e. another thread or interrupt). Once the notification has been signalled, all threads currently blocked on the object become unblocked and moved into the ready list.</p>
<p>Signalling a notification object that has no actively-waiting threads has no effect.</p>
<h1><a class="anchor" id="MSGMSGQ"></a>
Messages and Message Queues</h1>
<h2><a class="anchor" id="MESSAGES"></a>
Messages</h2>
<p>Sending messages between threads is the key means of synchronizing access to data, and the primary mechanism to perform asynchronous data processing operations.</p>
<p>Sending a message consists of the following operations:</p>
<ul>
<li>Obtain a Message object from a source message pool</li>
<li>Set the message data and event fields</li>
<li>Send the message to the destination message queue</li>
</ul>
<p>While receiving a message consists of the following steps:</p>
<ul>
<li>Wait for a messages in the destination message queue</li>
<li>Process the message data</li>
<li>Return the message back to the source message pool</li>
</ul>
<p>These operations, and the various data objects involved are discussed in more detail in the following section.</p>
<h2><a class="anchor" id="MESSAGEOBJ"></a>
Message Objects</h2>
<p>Message objects are used to communicate arbitrary data between threads in a safe and synchronous way.</p>
<p>The message object consists of an event code field and a data field. The event code is used to provide context to the message object, while the data field (essentially a void * data pointer) is used to provide a payload of data corresponding to the particular event.</p>
<p>Access to these fields is marshalled by accessors - the transmitting thread uses the SetData() and SetCode() methods to seed the data, while the receiving thread uses the GetData() and GetCode() methods to retrieve it.</p>
<p>By providing the data as a void data pointer instead of a fixed-size message, we achieve an unprecedented measure of simplicity and flexibility. Data can be either statically or dynamically allocated, and sized appropriately for the event without having to format and reformat data by both sending and receiving threads. The choices here are left to the user - and the kernel doesn't get in the way of efficiency.</p>
<p>It is worth noting that you can send messages to message queues from within ISR context. This helps maintain consistency, since the same APIs can be used to provide event-driven programming facilities throughout the whole of the OS.</p>
<h2><a class="anchor" id="MESSAGEQUEUES"></a>
Message Queues</h2>
<p>Message objects specify data with context, but do not specify where the messages will be sent. For this purpose we have a MessageQueue object. Sending an object to a message queue involves calling the MessageQueue::Send() method, passing in a pointer to the Message object as an argument.</p>
<p>When a message is sent to the queue, the first thread blocked on the queue (as a result of calling the MessageQueue Receive() method) will wake up, with a pointer to the Message object returned.</p>
<p>It's worth noting that multiple threads can block on the same message queue, providing a means for multiple threads to share work in parallel.</p>
<h2><a class="anchor" id="MAILBOXES"></a>
Mailboxes</h2>
<p>Another form of IPC is provided by <a class="el" href="namespace_mark3.html">Mark3</a>, in the form of Mailboxes and Envelopes. Mailboxes are similar to message queues in that they provide a synchronized interface by which data can be transmitted between threads.</p>
<p>Where Message Queues rely on linked lists of lightweight message objects (containing only message code and a void* data-pointer), which are inherently abstract, Mailboxes use a dedicated blob of memory, which is carved up into fixed-size chunks called Envelopes (defined by the user), which are sent and received. Unlike message queues, mailbox data is copied to and from the mailboxes dedicated pool.</p>
<p>Mailboxes also differ in that they provide not only a blocking "receive" call, but also a blocking "send" call, providing the opportunity for threads to block on "mailbox full" as well as "mailbox empty" conditions.</p>
<p>All send/receive APIs support an optional timeout parameter if the KERNEL_USE_TIMEOUTS option has been configured in <a class="el" href="mark3cfg_8h.html" title="Mark3 Kernel Configuration. ">mark3cfg.h</a></p>
<h2><a class="anchor" id="ATOMICOPS"></a>
Atomic Operations</h2>
<div class="image">
<img src="Mark3_arch25.png" alt="Mark3_arch25.png"/>
</div>
 <p>This utility class provides primatives for atomic operations - that is, operations that are guaranteed to execute uninterrupted. Basic atomic primatives provided here include Set/Add/Delete for 8, 16, and 32-bit integer types, as well as an atomic test-and-set.</p>
<h2><a class="anchor" id="DRIVERS"></a>
Drivers</h2>
<div class="image">
<img src="Mark3_arch18.png" alt="Mark3_arch18.png"/>
</div>
 <p>This is the basis of the driver framework. In the context of <a class="el" href="namespace_mark3.html">Mark3</a>, drivers don't necessarily have to be based on physical hardware peripherals. They can be used to represent algorithms (such as random number generators), files, or protocol stacks. Unlike FunkOS, where driver IO is protected automatically by a mutex, we do not use this kind of protection - we leave it up to the driver implementor to do what's right in its own context. This also frees up the driver to implement all sorts of other neat stuff, like sending messages to threads associated with the driver. Drivers are implemented as character devices, with the standard array of posix-style accessor methods for reading, writing, and general driver control.</p>
<p>A global driver list is provided as a convenient and minimal "filesystem" structure, in which devices can be accessed by name.</p>
<p><b>Driver Design</b></p>
<p>A device driver needs to be able to perform the following operations:</p>
<ul>
<li>Initialize a peripheral</li>
<li>Start/stop a peripheral</li>
<li>Handle I/O control operations</li>
<li>Perform various read/write operations</li>
</ul>
<p>At the end of the day, that's pretty much all a device driver has to do, and all of the functionality that needs to be presented to the developer.</p>
<p>We abstract all device drivers using a base-class which implements the following methods:</p>
<ul>
<li>Start/Open</li>
<li>Stop/Close</li>
<li>Control</li>
<li>Read</li>
<li>Write</li>
</ul>
<p>A basic driver framework and API can thus be implemented in five function calls - that's it! You could even reduce that further by handling the initialize, start, and stop operations inside the "control" operation.</p>
<p><b>Driver API</b></p>
<p>In C++, we can implement this as a class to abstract these event handlers, with virtual void functions in the base class overridden by the inherited objects.</p>
<p>To add and remove device drivers from the global table, we use the following methods: </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code" href="namespace_mark3_1_1_atomic.html#a874e5f6962711faf76664c409e26e2ce">DriverList::Add</a>( Driver *pclDriver_ );</div><div class="line"><span class="keywordtype">void</span> DriverList::Remove( Driver *pclDriver_ );</div></div><!-- fragment --><p><a class="el" href="namespace_mark3_1_1_atomic.html#a874e5f6962711faf76664c409e26e2ce" title="Add Add a value to a variable in an uninterruptable operation. ">DriverList::Add()</a>/Remove() takes a single argument - the pointer to the object to operate on.</p>
<p>Once a driver has been added to the table, drivers are opened by NAME using DriverList::FindByName("/dev/name"). This function returns a pointer to the specified driver if successful, or to a built in /dev/null device if the path name is invalid. After a driver is open, that pointer is used for all other driver access functions.</p>
<p>This abstraction is incredibly useful - any peripheral or service can be accessed through a consistent set of APIs, that make it easy to substitute implementations from one platform to another. Portability is ensured, the overhead is negligible, and it emphasizes the reuse of both driver and application code as separate entities.</p>
<p>Consider a system with drivers for I2C, SPI, and UART peripherals - under our driver framework, an application can initialize these peripherals and write a greeting to each using the same simple API functions for all drivers:</p>
<div class="fragment"><div class="line">pclI2C  = DriverList::FindByName(<span class="stringliteral">&quot;/dev/i2c&quot;</span>);</div><div class="line">pclUART = DriverList::FindByName(<span class="stringliteral">&quot;/dev/tty0&quot;</span>);</div><div class="line">pclSPI  = DriverList::FindByName(<span class="stringliteral">&quot;/dev/spi&quot;</span>);</div><div class="line"></div><div class="line">pclI2C-&gt;Write(12,<span class="stringliteral">&quot;Hello World!&quot;</span>);</div><div class="line">pclUART-&gt;Write(12, <span class="stringliteral">&quot;Hello World!&quot;</span>);</div><div class="line">pclSPI-&gt;Write(12, <span class="stringliteral">&quot;Hello World!&quot;</span>);</div></div><!-- fragment --><h1><a class="anchor" id="KRNLPROPER"></a>
Kernel Proper and Porting</h1>
<div class="image">
<img src="Mark3_arch26.png" alt="Mark3_arch26.png"/>
</div>
 <p>The Kernel class is a static class with methods to handle the initialization and startup of the RTOS, manage errors, and provide user-hooks for fatal error handling (functions called when Kernel::Panic() conditions are encountered), or when the Idle function is run.</p>
<p>Internally, Kernel::Init() calls the initialization routines for various kernel objects, providing a single interface by which all RTOS-related system initialization takes place.</p>
<p>Kernel::Start() is called to begin running OS funcitonality, and does not return. Control of the CPU is handed over to the scheduler, and the highest-priority ready thread begins execution in the RTOS environment.</p>
<p><b>Harware Abstraction Layer</b></p>
<p>Almost all of the <a class="el" href="namespace_mark3.html">Mark3</a> kernel (and middleware) is completely platform independent, and should compile cleanly on any platform with a modern C++ compiler. However, there are a few areas within <a class="el" href="namespace_mark3.html">Mark3</a> that can only be implemented by touching hardware directly.</p>
<p>These interfaces generally cover four features:</p><ul>
<li>Thread initializaiton and context-switching logic</li>
<li>Software interrupt control (used to generate context switches)</li>
<li>Hardware timer control (support for time-based functionlity, such as Sleep())</li>
<li>Code-execution profiling timer (not necessary to port if code-profiling is not compiled into the kernel)</li>
</ul>
<p>The hardware abstraction layer in <a class="el" href="namespace_mark3.html">Mark3</a> provides a consistent interface for each of these four features. <a class="el" href="namespace_mark3.html">Mark3</a> is ported to new target architectures by providing an implementation for all of the interfaces declared in the abstraction layer. In the following section, we will explore how this was used to port the kernel to ARM Cortex-M0.</p>
<p><b>Real-world Porting Example – Cortex M0</b></p>
<p>This section serves as a real-world example of how <a class="el" href="namespace_mark3.html">Mark3</a> can be ported to new architectures, how the <a class="el" href="namespace_mark3.html">Mark3</a> abstraction layer works, and as a practical reference for using the RTOS support functionality baked in modern ARM Cortex-M series microcontrollers. Most of this documentation here is taken directly from the source code found in the /kernel/cpu/cm0/ ports directory, with additional annotations to explain the port in more detail. Note that a familiarity with Cortex-M series parts will go a long way to understanding the subject matter presented, especially a basic understanding of the ARM CPU registers, exception models, and OS support features (PendSV, SysTick and SVC). If you're unfamiliar with ARM architecture, pay attention to the comments more than the source itself to illustrate the concepts.</p>
<p>Porting <a class="el" href="namespace_mark3.html">Mark3</a> to a new architecture consists of a few basic pieces; for developers familiar with the target architecture and the porting process, it's not a tremendously onerous endeavour to get <a class="el" href="namespace_mark3.html">Mark3</a> up-and-running somewhere new. For starters, all non-portable components are completely isolated in the source-tree under:</p>
<p>/embedded/kernel/CPU/VARIANT/TOOLCHAIN/,</p>
<p>where CPU is the architecture, VARIANT is the vendor/part, and TOOLCHAIN is the compiler tool suite used to build the code.</p>
<p>From within the specific port folder, a developer needs only implement a few classes and headers that define the port-specific behavior of <a class="el" href="namespace_mark3.html">Mark3</a>:</p>
<ul>
<li>KernelSWI (<a class="el" href="kernelswi_8cpp.html" title="Kernel Software interrupt implementation for ATMega328p. ">kernelswi.cpp</a>/kernelswi.h) - Provides a maskable software-triggered interrupt used to perform context switching.</li>
<li>KernelTimer (<a class="el" href="kerneltimer_8cpp.html" title="Kernel Timer Implementation for ATMega328p. ">kerneltimer.cpp</a>/kerneltimer.h) - Provides either a fixed-frequency or programmable-interval timer, which triggers an interrupt on expiry. This is used for implementing round-robin scheduling, thread-sleeps, and generic software timers.</li>
<li>Profiler (kprofile.cpp/kprofile.h) - Contains code for runtime code-profiling. This is optional and may be stubbed out if left unimplemented (we won't cover profiling timers here).</li>
<li>ThreadPort (<a class="el" href="threadport_8cpp.html" title="ATMega1284p Multithreading. ">threadport.cpp</a>/threadport.h) - The meat-and-potatoes of the port code lives here. This class contains architecture/part-specific code used to initialize threads, implement critical-sections, perform context-switching, and start the kernel. Most of the time spent in this article focuses on the code found here.</li>
</ul>
<p>Summarizing the above, these modules provide the following list of functionality: </p><pre class="fragment">- Thread stack initialization
- Kernel startup and first thread entry
- Context switch and SWI
- Kernel timers
- Critical Sections
.
</pre><p>The implementation of each of these pieces will be analyzed in detail in the sections that follow.</p>
<p><b>Thread Stack Initialization</b></p>
<p>Before a thread can be used, its stack must first be initialized to its default state. This default state ensures that when the thread is scheduled for the first time and its context restored, that it will cause the CPU to jump to the user's specified entry-point function.</p>
<p>All of the platform independent thread setup is handled by the generic kernel code. However, since every CPU architecture has its own register set, and stacks different information as part of an interrupt/exception, we have to implement this thread setup code for each platform we want the kernel to support (Combination of Architecture + Variant + Toolchain).</p>
<p>In the ARM Cortex-M0 architecture, the stack frame consists of the following information:</p>
<p>a) Exception Stack Frame</p>
<p>Contains the 8 registers which the ARM Cortex-M0 CPU automatically pushes to the stack when entering an exception. The following registers are included (in stack'd order):</p>
<pre class="fragment">    [ XPSR ] &lt;-- Highest address in context
    [ PC   ]
    [ LR   ]
    [ R12  ]
    [ R3   ]
    [ R2   ]
    [ R1   ]
    [ R0   ]
</pre><p>XPSR – This is the CPU's status register. We need to set this to 0x01000000 (the "T" bit), which indicates that the CPU is executing in “thumb” mode. Note that ARMv6m and ARMv7m processors only run thumb2 instructions, so an exception is liable to occur if this bit ever gets cleared.</p>
<p>PC – Program Counter. This should be set with the initial entry point (function pointer) for that the user wishes to start executing with this thread.</p>
<p>LR - The base link register. Normally, this register contains the return address of the calling function, which is where the CPU jumps when a function returns. However, our threads generally don't return (and if they do, they're placed into the stop state). As a result we can leave this as 0.</p>
<p>The other registers in the stack frame are generic working registers, and have no special meaning, with the exception that R0 will hold the user's argument value passed into the entrypoint.</p>
<p>b) Complimentary CPU Register Context</p>
<pre class="fragment">    [ R11   ]
    ...
    [ R4    ] &lt;-- Lowest address in context
</pre><p>These are the other general-purpose CPU registers that need to be backed up/ restored on a context switch, but aren't stacked by default on a Cortex-M0 exception. If there were any additional hardware registers to back up, then we'd also have to include them in this part of the context as well.</p>
<p>As a result, these registers all need to be manually pushed to the stack on stack creation, and will need to be explicitly pushed and pop as part of a normal context switch.</p>
<p>With this default exception state in mind, the following code is used to initialize a thread's stack for a Cortex-M0.</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> ThreadPort::InitStack(Thread *pclThread_)</div><div class="line">{</div><div class="line">    K_ULONG *pulStack;</div><div class="line">    K_ULONG *pulTemp;</div><div class="line">    K_ULONG ulAddr;</div><div class="line">    K_USHORT i;</div><div class="line"></div><div class="line">    <span class="comment">// Get the entrypoint for the thread</span></div><div class="line">    ulAddr = (K_ULONG)(pclThread_-&gt;m_pfEntryPoint);</div><div class="line"></div><div class="line">    <span class="comment">// Get the top-of-stack pointer for the thread</span></div><div class="line">    pulStack = (K_ULONG*)pclThread_-&gt;m_pwStackTop;</div><div class="line"></div><div class="line">    <span class="comment">// Initialize the stack to all FF&#39;s to aid in stack depth checking</span></div><div class="line">    pulTemp = (K_ULONG*)pclThread_-&gt;m_pwStack;</div><div class="line">    <span class="keywordflow">for</span> (i = 0; i &lt; pclThread_-&gt;m_usStackSize / <span class="keyword">sizeof</span>(K_ULONG); i++)</div><div class="line">    {</div><div class="line">        pulTemp[i] = 0xFFFFFFFF;</div><div class="line">    }</div><div class="line"></div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0);             <span class="comment">// Apply one word of padding</span></div><div class="line"></div><div class="line">    <span class="comment">//-- Simulated Exception Stack Frame --</span></div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x01000000);    <span class="comment">// XSPR;set &quot;T&quot; bit for thumb-mode</span></div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, ulAddr);        <span class="comment">// PC</span></div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0);             <span class="comment">// LR</span></div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x12);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x3);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x2);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x1);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, (K_ULONG)pclThread_-&gt;m_pvArg);    <span class="comment">// R0 = argument</span></div><div class="line"></div><div class="line">    <span class="comment">//-- Simulated Manually-Stacked Registers --</span></div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x11);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x10);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x09);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x08);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x07);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x06);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x05);</div><div class="line">    <a class="code" href="threadport_8h.html#a15c68cf3ebfae7f24ef7bc0e20010fc7">PUSH_TO_STACK</a>(pulStack, 0x04);</div><div class="line">    pulStack++;</div><div class="line"></div><div class="line">    pclThread_-&gt;m_pwStackTop = pulStack;</div><div class="line">}</div></div><!-- fragment --><p><b>Kernel Startup</b></p>
<p>The same general process applies to starting the kernel on an ARM Cortex-M0 as on other platforms. Here, we initialize and start the platform specific timer and software-interrupt modules, find the first thread to run, and then jump to that first thread.</p>
<p>Now, to perform that last step, we have two options:</p>
<p>1) Simulate a return from an exception manually to start the first thread, or.. 2) Use a software interrupt to trigger the first "Context Restore/Return from
   Interrupt"</p>
<p>For 1), we basically have to restore the whole stack manually, not relying on the CPU to do any of this for us. That's certainly doable, but not all Cortex parts support this (other members of the family support privileged modes, etc.). That, and the code required to do this is generally more complex due to all of the exception-state simulation. So, we will opt for the second option instead.</p>
<p>To implement a software to start our first thread, we will use the SVC instruction to generate an exception. From that exception, we can then restore the context from our first thread, set the CPU up to use the right “process” stack, and return-from-exception back to our first thread. We'll explore the code for that later.</p>
<p>But, before we can call the SVC exception, we're going to do a couple of things.</p>
<p>First, we're going to reset the default MSP stack pointer to its original top-of-stack value. The rationale here is that we no longer care about the data on the MSP stack, since calling the SVC instruction triggers a chain of events from which we never return. The MSP is also used by all exception-handling, so regaining a few words of stack here can be useful. We'll also enable all maskable exceptions at this point, since this code results in the kernel being started with the CPU executing the RTOS threads, at which point a user would expect interrupts to be enabled.</p>
<p>Note, the default stack pointer location is stored at address 0x00000000 on all ARM Cortex M0 parts. That explains the code below...</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> ThreadPort_StartFirstThread( <span class="keywordtype">void</span> )</div><div class="line">{</div><div class="line">    <span class="keyword">asm</span>(</div><div class="line">        <span class="stringliteral">&quot; ldr r1, [r0] \n&quot;</span> <span class="comment">// Reset the MSP to the default base address</span></div><div class="line">        <span class="stringliteral">&quot; msr msp, r1 \n&quot;</span></div><div class="line">        <span class="stringliteral">&quot; cpsie i \n&quot;</span>      <span class="comment">// Enable interrupts</span></div><div class="line">        <span class="stringliteral">&quot; svc 0 \n&quot;</span>        <span class="comment">// Jump to SVC Call</span></div><div class="line">        );</div><div class="line">}</div></div><!-- fragment --><p><b>First Thread Entry</b></p>
<p>This handler has the job of taking the first thread object's stack, and restoring the default state data in a way that ensures that the thread starts executing when returning from the call.</p>
<p>We also keep in mind that there's an 8-byte offset from the beginning of the thread object to the location of the thread stack pointer. This offset is a result of the thread object inheriting from the linked-list node class, which has 8-bytes of data. This is stored first in the object, before the first element of the class, which is the "stack top" pointer.</p>
<p>The following assembly code shows how the SVC call is implemented in <a class="el" href="namespace_mark3.html">Mark3</a> for the purpose of starting the first thread.</p>
<div class="fragment"><div class="line">get_thread_stack:</div><div class="line">    ; Get the stack pointer <span class="keywordflow">for</span> the current thread</div><div class="line">    ldr r0, g_pstCurrent</div><div class="line">    ldr r1, [r0]</div><div class="line">    add r1, #8</div><div class="line">    ldr r2, [r1]         ; r2 contains the current stack-top</div><div class="line"></div><div class="line">load_manually_placed_context_r11_r8:</div><div class="line">    ; Handle the bottom 32-bytes of the stack frame</div><div class="line">    ; Start with r11-r8, because only r0-r7 can be used</div><div class="line">    ; with ldmia on CM0.</div><div class="line">    add r2, #16</div><div class="line">    ldmia r2!, {r4-r7}</div><div class="line">    mov r11, r7</div><div class="line">    mov r10, r6</div><div class="line">    mov r9, r5</div><div class="line">    mov r8, r4</div><div class="line"></div><div class="line">set_psp:</div><div class="line">    ; Since r2 is coincidentally back to where the stack pointer should be,</div><div class="line">    ; <a class="code" href="namespace_mark3_1_1_atomic.html#a42c7da32b722030be55fe0b5b62df3f3">Set</a> the program stack pointer such that returning from the exception handler</div><div class="line">    msr psp, r2</div><div class="line"></div><div class="line">load_manually_placed_context_r7_r4:</div><div class="line">    ; Get back to the bottom of the manually stacked registers and pop.</div><div class="line">    sub r2, #32</div><div class="line">    ldmia r2!, {r4-r7}  ; Register r4-r11 are restored.</div><div class="line"></div><div class="line">set_thread_and_privilege_modes:</div><div class="line">    ; Also modify the control <span class="keyword">register</span> to force use of thread mode as well</div><div class="line">    ; For CM3 forward-compatibility, also <span class="keyword">set</span> user mode.</div><div class="line">    mrs r0, control</div><div class="line">    mov r1, #0x03</div><div class="line">    orr r0, r1</div><div class="line">    control, r0</div><div class="line"></div><div class="line">set_lr:</div><div class="line">    ; <a class="code" href="namespace_mark3_1_1_atomic.html#a42c7da32b722030be55fe0b5b62df3f3">Set</a> up the link <span class="keyword">register</span> such that on <span class="keywordflow">return</span>, the code operates</div><div class="line">    ; in thread mode <span class="keyword">using</span> the PSP. To <span class="keywordflow">do</span> <span class="keyword">this</span>, we or 0x0D to the value stored</div><div class="line">    ; in the lr by the exception hardware EXC_RETURN. Alternately, we could</div><div class="line">    ; just force lr to be 0xFFFFFFFD (we know that<span class="stringliteral">&#39;s what we want from the</span></div><div class="line"><span class="stringliteral">    ; hardware, anyway)</span></div><div class="line"><span class="stringliteral">    mov  r0, #0x0D</span></div><div class="line"><span class="stringliteral">    mov  r1, lr</span></div><div class="line"><span class="stringliteral">    orr r0, r1</span></div><div class="line"><span class="stringliteral"></span></div><div class="line"><span class="stringliteral">exit_exception:</span></div><div class="line"><span class="stringliteral">    ; Return from the exception handler.</span></div><div class="line"><span class="stringliteral">    ; The CPU will automagically unstack R0-R3, R12, PC, LR, and xPSR</span></div><div class="line"><span class="stringliteral">    ; for us.  If all goes well, our thread will start execution at the</span></div><div class="line"><span class="stringliteral">    ; entrypoint, with the us-specified argument.</span></div><div class="line"><span class="stringliteral">    bx r0</span></div></div><!-- fragment --><p>On ARM Cortex parts, there's dedicated hardware that's used primarily to support RTOS (or RTOS-like) funcationlity. This functionality includes the SysTick timer, and the PendSV Exception. SysTick is used for a tick-based kernel timer, while the PendSV exception is used for performing context switches. In reality, it's a "special SVC" call that's designed to be lower-overhead, in that it isn't mux'd with a bunch of other system or application functionality.</p>
<p>So how do we go about actually implementing a context switch here? There are a lot of different parts involved, but it essentially comes down to 3 steps:</p>
<p>1) Saving the context. </p><pre class="fragment">Thread's top-of-stack value is stored, all registers are stacked.  We're
good to go!
</pre><p>2) Swap threads </p><pre class="fragment">We swap the Scheduler's “next” thread with the “current” thread.
</pre><p>3) Restore Context </p><pre class="fragment">This is more or less identical to what we did when restoring the first
context.  Some operations may be optimized for data already stored in
registers.
</pre><p>The code used to implement these steps on Cortex-M0 is presented below:</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> PendSV_Handler(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    <a class="code" href="threadport_8h.html#a29b07011504fc457d8e139d8a38ffaba">ASM</a>(</div><div class="line">    <span class="comment">// Thread_SaveContext()</span></div><div class="line">    <span class="stringliteral">&quot; ldr r1, CURR_ \n&quot;</span></div><div class="line">    <span class="stringliteral">&quot; ldr r1, [r1] \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r3, r1 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; add r3, #8 \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">//  Grab the psp and adjust it by 32 based on extra registers we&#39;re going</span></div><div class="line">    <span class="comment">// to be manually stacking.</span></div><div class="line">    <span class="stringliteral">&quot; mrs r2, psp \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; sub r2, #32 \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// While we&#39;re here, store the new top-of-stack value</span></div><div class="line">    <span class="stringliteral">&quot; str r2, [r3] \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// And, while r2 is at the bottom of the stack frame, stack r7-r4</span></div><div class="line">    <span class="stringliteral">&quot; stmia r2!, {r4-r7} \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// Stack r11-r8</span></div><div class="line">    <span class="stringliteral">&quot; mov r7, r11 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r6, r10 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r5, r9 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r4, r8 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; stmia r2!, {r4-r7} \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// Equivalent of Thread_Swap() - performs g_pstCurrent = g_pstNext</span></div><div class="line">    <span class="stringliteral">&quot; ldr r1, CURR_ \n&quot;</span></div><div class="line">    <span class="stringliteral">&quot; ldr r0, NEXT_ \n&quot;</span></div><div class="line">    <span class="stringliteral">&quot; ldr r0, [r0] \n&quot;</span></div><div class="line">    <span class="stringliteral">&quot; str r0, [r1] \n&quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// Thread_RestoreContext()</span></div><div class="line">    <span class="comment">// Get the pointer to the next thread&#39;s stack</span></div><div class="line">    <span class="stringliteral">&quot; add r0, #8 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; ldr r2, [r0] \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// Stack pointer is in r2, start loading registers from</span></div><div class="line">    <span class="comment">// the &quot;manually-stacked&quot; set</span></div><div class="line">    <span class="comment">// Start with r11-r8, since these can&#39;t be accessed directly.</span></div><div class="line">    <span class="stringliteral">&quot; add r2, #16 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; ldmia r2!, {r4-r7} \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r11, r7 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r10, r6 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r9, r5 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; mov r8, r4 \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// After subbing R2 #16 manually, and #16 through ldmia, our PSP is where it</span></div><div class="line">    <span class="comment">// needs to be when we return from the exception handler</span></div><div class="line">    <span class="stringliteral">&quot; msr psp, r2 \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// Pop manually-stacked R4-R7</span></div><div class="line">    <span class="stringliteral">&quot; sub r2, #32 \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; ldmia r2!, {r4-r7} \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// lr contains the proper EXC_RETURN value</span></div><div class="line">    <span class="comment">// we&#39;re done with the exception, so return back to newly-chosen thread</span></div><div class="line">    <span class="stringliteral">&quot; bx lr \n &quot;</span></div><div class="line">    <span class="stringliteral">&quot; nop \n &quot;</span></div><div class="line"></div><div class="line">    <span class="comment">// Must be 4-byte aligned.</span></div><div class="line">    <span class="stringliteral">&quot; NEXT_: .word g_pstNext \n&quot;</span></div><div class="line">    <span class="stringliteral">&quot; CURR_: .word g_pstCurrent \n&quot;</span></div><div class="line">    );</div><div class="line">}</div></div><!-- fragment --><p><b>Kernel Timers</b></p>
<p>ARM Cortex-M series microcontrollers each contain a SysTick timer, which was designed to facilitate a fixed-interval RTOS timer-tick. This timer is a precise 24-bit down-count timer, run at the main CPU clock frequency, that can be programmed to trigger an exception when the timer expires. The handler for this exception can thus be used to drive software timers throughout the system on a fixed interval.</p>
<p>Unfortunately, this hardware is extremely simple, and does not offer the flexibility of other timer hardware commonly implemented by MCU vendors - specifically a suitable timer prescalar that can be used to generate efficient, long-counting intervals. As a result, while the "generic" port of <a class="el" href="namespace_mark3.html">Mark3</a> for Cortex-M0 leverages the common SysTick timer interface, it only supports the tick-based version of the kernel's timer (note that specific Cortex-M0 ports such as the Atmel SAMD20 do have tickless timers).</p>
<p>Setting up a tick-based KernelTimer class to use the SysTick timer is, however, extremely easy, as is illustrated below:</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> KernelTimer::Start(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    SysTick_Config(<a class="code" href="portcfg_8h.html#a49e8015a9f203e27d21519381679e109">PORT_SYSTEM_FREQ</a> / 1000); <span class="comment">// 1KHz fixed clock...</span></div><div class="line">    NVIC_EnableIRQ(SysTick_IRQn);</div><div class="line">}</div><div class="line"></div><div class="line">In <span class="keyword">this</span> instance, the call to SysTick_Config() generates a 1kHz system-tick</div><div class="line">signal, and the NVIC_EnableIRQ() call ensures that a SysTick exception is</div><div class="line">generated for each tick.  All other functions in the Cortex version of the</div><div class="line">KernelTimer class are essentially stubbed out (see the source for more details).</div><div class="line"></div><div class="line">Note that the functions used in this call are part of the ARM Cortex</div><div class="line">Microcontroller Software Interface Standard (cmsis), and are supplied by all</div><div class="line">parts vendors selling Cortex hardware.  This greatly simplifies the design</div><div class="line">of our port-code, since we can be reasonably assured that these APIs will</div><div class="line">work the same on all devices.</div><div class="line"></div><div class="line">The handler code called when a SysTick exception occurs is basically the</div><div class="line">same as on other platforms (such as <a class="code" href="portcfg_8h.html#a1519396040c1c9c28f597ccfbae61843">AVR</a>), except that we explicitly clear the</div><div class="line">&quot;exception pending&quot; bit before returning.  This is implemented in the</div><div class="line">following code:</div><div class="line"></div><div class="line">@code{.cpp}</div><div class="line"><span class="keywordtype">void</span> SysTick_Handler(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line"><span class="preprocessor">#if KERNEL_USE_TIMERS</span></div><div class="line">    TimerScheduler::Process();</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"><span class="preprocessor">#if KERNEL_USE_QUANTUM</span></div><div class="line">    Quantum::UpdateTimer();</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"></div><div class="line">    <span class="comment">// Clear the systick interrupt pending bit.</span></div><div class="line">    SCB-&gt;ICSR |= SCB_ICSR_PENDSTCLR_Msk;</div><div class="line">}</div></div><!-- fragment --><p><b>Critical Sections</b></p>
<p>A "critical section" is a block of code whose execution cannot be interrupted by means of context switches or an interrupt. In a traditional single-core operating system, it is typically implemented as a block of code where the interrupts are disabled - this is also the approach taken by <a class="el" href="namespace_mark3.html">Mark3</a>. Given that every CPU has its own means of disabling/enabling interrupts, the implementation of the critical section APIs is also non-portable.</p>
<p>In the Cortex-M0 port, we implement the two critical section APIs (<a class="el" href="threadport_8h.html#aa471650be7322fc62d4f037157374bd3" title="These macros must be used in pairs ! ">CS_ENTER()</a> and <a class="el" href="threadport_8h.html#a107ddca47f143df4e7c60898a2916f98" title="Exit critical section (restore status register) ">CS_EXIT()</a>) as function-like macros containing inline assembly. All uses of these calls are called in pairs within a function and must take place at the same level-of-scope. Also, as nesting may occur (critical section within a critical section), this must be taken into account in the code.</p>
<p>In general, <a class="el" href="threadport_8h.html#aa471650be7322fc62d4f037157374bd3" title="These macros must be used in pairs ! ">CS_ENTER()</a> performs the following tasks: </p><pre class="fragment">- Cache the current interrupt-enabled state within a local variable in the
thread's state
- Disable interrupts
.
</pre><p>Conversely, <a class="el" href="threadport_8h.html#a107ddca47f143df4e7c60898a2916f98" title="Exit critical section (restore status register) ">CS_EXIT()</a> performs the following tasks: </p><pre class="fragment">- Read the original interrupt-enabled state from the cached value
- Restore interrupts to the original value
.
</pre><p>On Cortex-M series micrcontrollers, the PRIMASK special register contains a single status bit which can be used to enable/disable all maskable interrupts at once. This register can be read directly to examine or modify its state. For convenience, ARMv6m provides two instructions to enable/disable interrupts</p><ul>
<li>cpsid (disable interrupts) and cpsie (enable interrupts). <a class="el" href="namespace_mark3.html">Mark3</a> Implements these steps according to the following code:</li>
</ul>
<div class="fragment"><div class="line"><span class="comment">//------------------------------------------------------------------------</span></div><div class="line"><span class="comment"></span><span class="preprocessor">#define CS_ENTER()    \</span></div><div class="line"><span class="preprocessor">{    \</span></div><div class="line"><span class="preprocessor">    K_ULONG __ulRegState;    \</span></div><div class="line"><span class="preprocessor">    asm    ( \</span></div><div class="line"><span class="preprocessor">    &quot; mrs r0, PRIMASK \n&quot;    \</span></div><div class="line"><span class="preprocessor">    &quot; mov %[STATUS], r0 \n&quot; \</span></div><div class="line"><span class="preprocessor">    &quot; cpsid i \n &quot;    \</span></div><div class="line"><span class="preprocessor">    : [STATUS] &quot;=r&quot; (__ulRegState) \</span></div><div class="line"><span class="preprocessor">    );</span></div><div class="line"></div><div class="line"><span class="comment">//------------------------------------------------------------------------</span></div><div class="line"><span class="comment"></span><span class="preprocessor">#define CS_EXIT() \</span></div><div class="line"><span class="preprocessor">    asm    ( \</span></div><div class="line"><span class="preprocessor">    &quot; mov r0, %[STATUS] \n&quot; \</span></div><div class="line"><span class="preprocessor">    &quot; msr primask, r0 \n&quot;    \</span></div><div class="line"><span class="preprocessor">    : \</span></div><div class="line"><span class="preprocessor">    : [STATUS] &quot;r&quot; (__ulRegState) \</span></div><div class="line"><span class="preprocessor">    ); \</span></div><div class="line"><span class="preprocessor">}</span></div></div><!-- fragment --><p><b>Summary</b></p>
<p>In this section we have investigated how the main non-portable areas of the <a class="el" href="namespace_mark3.html">Mark3</a> RTOS are implemented on a Cortex-M0 microcontroller. <a class="el" href="namespace_mark3.html">Mark3</a> leverages all of the hardware blocks designed to enable RTOS functionality on ARM Cortex-M series microcontrollers: the SVC call provides the mechanism by which we start the kernel, the PendSV exception provides the necessary software interrupt, and the SysTick timer provides an RTOS tick. As a result, <a class="el" href="namespace_mark3.html">Mark3</a> is a perfect fit for these devices - and as a result of this approach, the same RTOS port code should work with little to no modification on all ARM Cortex-M parts.</p>
<p>We have discussed what functionality in the RTOS is not portable, and what interfaces must be implemented in order to complete a fully-functional port. The five specific areas which are non-portable (stack initialization, kernel startup/entry, kernel timers, context switching, and critical sections) have been discussed in detail, with the platform-specifc source provided as a practical reference to ARM-specific OS features, as well as <a class="el" href="namespace_mark3.html">Mark3</a>'s porting infrastructure. From this example (and the accompanying source), it should be possible for an experienced developers to create a port <a class="el" href="namespace_mark3.html">Mark3</a> to other microcontroller targets. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Mar 7 2019 19:45:15 for Mark3 Realtime Kernel by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
